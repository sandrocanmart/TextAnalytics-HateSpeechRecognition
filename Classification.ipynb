{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a021cd1d",
   "metadata": {},
   "source": [
    "# Classification \n",
    "\n",
    "- scegliere classificatori\n",
    "- prova bilanciamento classi\n",
    "- prova incremento performance con metadati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3db451",
   "metadata": {},
   "source": [
    "class da provare:\n",
    "- Gaussian Naive Bayes, Decision Tree, K Nearest Neighbors, Random Forest, SVM, logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e58d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ci sono diversi metodi di estrazione delle feature dal testo, o rappresentazione del testo, che convertono il testo in una forma numerica comprensibile dai modelli di machine learning. Alcuni dei metodi più comuni includono:\n",
    "\n",
    "1. **Bag of Words (BoW):**\n",
    "   - **Descrizione:** Questo è uno dei metodi più semplici. Si crea un \"sacchetto di parole\" che contiene tutte le parole uniche nel corpus di testo. La rappresentazione di ciascun documento è quindi un vettore che conta quante volte ciascuna parola appare nel documento.\n",
    "   - **Librerie:** `CountVectorizer` di scikit-learn.\n",
    "\n",
    "2. **Term Frequency-Inverse Document Frequency (TF-IDF):**\n",
    "   - **Descrizione:** Questo metodo assegna un peso a ciascuna parola in base alla sua frequenza nel documento (Term Frequency) e alla sua rarità nell'intero corpus (Inverse Document Frequency). In questo modo, le parole comuni otterranno pesi più bassi rispetto a quelle più rare.\n",
    "   - **Librerie:** `TfidfVectorizer` di scikit-learn.\n",
    "\n",
    "3. **Word Embeddings (Word2Vec, GloVe, FastText):**\n",
    "   - **Descrizione:** Questi modelli apprendono rappresentazioni vettoriali densi delle parole attraverso il contesto in cui compaiono. Ciascuna parola è mappata in uno spazio vettoriale continuo, e la somiglianza semantica tra le parole viene catturata dalla distanza in questo spazio.\n",
    "   - **Librerie:** `gensim` per Word2Vec, `spaCy` per GloVe, e `fastText` per FastText.\n",
    "\n",
    "4. **Doc2Vec:**\n",
    "   - **Descrizione:** Una estensione di Word2Vec che estende la rappresentazione vettoriale alle frasi o ai documenti interi, assegnando un vettore unico a ciascun documento.\n",
    "   - **Librerie:** `gensim` fornisce un'implementazione di Doc2Vec.\n",
    "\n",
    "5. **N-grams:**\n",
    "   - **Descrizione:** Questo metodo considera sequenze contigue di N parole come feature anziché singole parole. Ad esempio, per N=2, considererai coppie di parole (bigrammi) come feature.\n",
    "   - **Librerie:** `CountVectorizer` di scikit-learn supporta l'estrazione di n-grammi.\n",
    "\n",
    "6. **Hashing Vectorizer:**\n",
    "   - **Descrizione:** Questo è un metodo di hashing che converte le parole in feature utilizzando una funzione hash. Aiuta a ridurre la dimensionalità dello spazio delle feature.\n",
    "   - **Librerie:** `HashingVectorizer` di scikit-learn.\n",
    "\n",
    "7. **Embedding Pre-trainati:**\n",
    "   - **Descrizione:** Puoi utilizzare modelli di embedding pre-addestrati su grandi corpus di testo (come Word2Vec pre-addestrato su Google News) e utilizzare queste rappresentazioni come feature per i tuoi dati.\n",
    "   - **Librerie:** `gensim`, `spaCy`, e altri per l'uso di modelli pre-addestrati.\n",
    "\n",
    "La scelta del metodo dipende spesso dal tipo di dati, dalla dimensione del dataset, e dagli obiettivi specifici del tuo task di machine learning. Esperimenti con diversi approcci possono aiutarti a determinare quale funziona meglio per il tuo caso specifico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6dbd27",
   "metadata": {},
   "source": [
    "**provare classificatori e poi vedere se i metadati aiutano ad aumentare accuracy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4cf7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score, cross_val_predict, train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, learning_curve\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78a1bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>is_hate_speech</th>\n",
       "      <th>dataset</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>anonymized_user_id</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>anonymized_description</th>\n",
       "      <th>Weighted_Engagement</th>\n",
       "      <th>lunghezza_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217874450618134</td>\n",
       "      <td>con tutte le denunce che si sta beccando salv...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.868893e+14</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>554.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>Avete presente quegli stereotipi sui siciliani...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360042217507605</td>\n",
       "      <td>prescrizione  i tre magi hanno trovato laccord...</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>154.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.570741e+14</td>\n",
       "      <td>2011-10-26</td>\n",
       "      <td>35043.0</td>\n",
       "      <td>10838.0</td>\n",
       "      <td>4535.0</td>\n",
       "      <td>Prof di latino e Deputata PD.Ama lo sport la R...</td>\n",
       "      <td>211.4</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>817917484817935</td>\n",
       "      <td>il m5s ha votato contro le unionicivili adduce...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>195.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.908473e+14</td>\n",
       "      <td>2009-09-24</td>\n",
       "      <td>139750.0</td>\n",
       "      <td>7971.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>Medico, appassionato di Cinema d'Autore, Music...</td>\n",
       "      <td>288.9</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172580609652325</td>\n",
       "      <td>la lega e il m5s stanno dando a bere allopinio...</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>112.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.027930e+14</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>8493.0</td>\n",
       "      <td>5303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145836038456701</td>\n",
       "      <td>che cosa cambia questa legge caro  con il decr...</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>45.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.308388e+14</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>11234.0</td>\n",
       "      <td>10815.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>Veneto! Assessore Regionale Sviluppo Economico...</td>\n",
       "      <td>65.4</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet_id                                              tweet  \\\n",
       "0  217874450618134   con tutte le denunce che si sta beccando salv...   \n",
       "1  360042217507605  prescrizione  i tre magi hanno trovato laccord...   \n",
       "2  817917484817935  il m5s ha votato contro le unionicivili adduce...   \n",
       "3  172580609652325  la lega e il m5s stanno dando a bere allopinio...   \n",
       "4  145836038456701  che cosa cambia questa legge caro  con il decr...   \n",
       "\n",
       "   is_hate_speech   dataset  created_at  retweet_count  favorite_count  \\\n",
       "0               1  politics  2018-08-11            0.0             6.0   \n",
       "1               0  politics  2018-11-08          154.0           448.0   \n",
       "2               1  politics  2018-11-10          195.0           638.0   \n",
       "3               0  politics  2018-11-22          112.0           377.0   \n",
       "4               0  politics  2018-12-02           45.0           143.0   \n",
       "\n",
       "                                              source  is_reply  is_retweet  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...       1.0         0.0   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...       0.0         0.0   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...       0.0         0.0   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...       0.0         0.0   \n",
       "4  <a href=\"http://twitter.com/#!/download/ipad\" ...       0.0         0.0   \n",
       "\n",
       "   is_quote  anonymized_user_id user_created_at  statuses_count  \\\n",
       "0       0.0        8.868893e+14      2018-04-01           554.0   \n",
       "1       0.0        2.570741e+14      2011-10-26         35043.0   \n",
       "2       0.0        6.908473e+14      2009-09-24        139750.0   \n",
       "3       0.0        9.027930e+14      2012-11-27          3356.0   \n",
       "4       0.0        5.308388e+14      2014-01-14         11234.0   \n",
       "\n",
       "   followers_count  friends_count  \\\n",
       "0            748.0          753.0   \n",
       "1          10838.0         4535.0   \n",
       "2           7971.0         1866.0   \n",
       "3           8493.0         5303.0   \n",
       "4          10815.0         1810.0   \n",
       "\n",
       "                              anonymized_description  Weighted_Engagement  \\\n",
       "0  Avete presente quegli stereotipi sui siciliani...                  1.9   \n",
       "1  Prof di latino e Deputata PD.Ama lo sport la R...                211.4   \n",
       "2  Medico, appassionato di Cinema d'Autore, Music...                288.9   \n",
       "3                                                NaN                169.1   \n",
       "4  Veneto! Assessore Regionale Sviluppo Economico...                 65.4   \n",
       "\n",
       "   lunghezza_tweet  \n",
       "0              120  \n",
       "1              252  \n",
       "2              255  \n",
       "3              244  \n",
       "4              193  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d4034",
   "metadata": {},
   "source": [
    "Data preprocessing\n",
    "\n",
    "Applying word embedding with the help of SKlearn's fucntion 'TFidfVectorizer', which turns a collection a documents, in this case, news articles, into a sparse matrix containing the vectors that represent the words in the document and their context and meaning\n",
    "\n",
    "\n",
    "**TfidfVectorizer e CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "790e8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a68136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([4668, 2332], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7000x135931 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 297703 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.3, random_state=0)\n",
    "\n",
    "TFvectorizer = TfidfVectorizer(stop_words='english',\n",
    "                               ngram_range=(1,2),\n",
    "                               max_df=.8,\n",
    "                               min_df=.0001\n",
    "                               )\n",
    "\n",
    "X_train = TFvectorizer.fit_transform(X_train)\n",
    "X_test = TFvectorizer.transform(X_test)\n",
    "\n",
    "# # In case CountVectorizer is preferred\n",
    "# Cntvectorizer = CountVectorizer(stop_words='english',\n",
    "#                                 ngram_range=(1,2),\n",
    "#                                 max_df=.8)\n",
    "\n",
    "# X_train = Cntvectorizer.fit_transform(X_train)\n",
    "# X_test = Cntvectorizer.transform(X_test)\n",
    "\n",
    "# Looking at the distribution of labels in the target variable, as well as info on the X_train matrix\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732d491",
   "metadata": {},
   "source": [
    "Quick-testing a model, to check if the vectorizing phase went well and a classifying model is able to correctly detect fake news. For this, a simple model with the default parameters is used.\n",
    "\n",
    "Aditionally, a classification report is produced together with a confusion matrix, a ROC curve and a Precision-Recall curve to further analyze the performance of the classifying task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ab21cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7691    0.8571    0.8107      2001\n",
      "           1     0.6286    0.4845    0.5472       999\n",
      "\n",
      "    accuracy                         0.7330      3000\n",
      "   macro avg     0.6988    0.6708    0.6789      3000\n",
      "weighted avg     0.7223    0.7330    0.7229      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits = 4))\n",
    "#da usare ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce8674",
   "metadata": {},
   "source": [
    "Testing several different models with cross-validation, to see if other models perform better regarding false negatives, and thus, the recall score. To evaluate them, a 10-fold cross validation approach is used to further avoid the unwanted introudction of bias to the model, expecting that the model fits the data well enough.\n",
    "\n",
    "After this evaluation, the precision recall curve, along with a plot to visualize their different metrics is produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a6273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the models to test\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_logreg = LogisticRegression()\n",
    "model_linsvc = LinearSVC()\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_paa = PassiveAggressiveClassifier()\n",
    "\n",
    "# Creating a dictionary with the models and their name to feed to the cross-validation evaluation\n",
    "models = {\n",
    "    'Decision Tree': model_dt,\n",
    "    'Logistic Regression': model_logreg,\n",
    "    'Linear SVM': model_linsvc,\n",
    "    'K-NearestNeighbors': model_knn,\n",
    "    'PassiveAgressive': model_paa\n",
    "    }\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bfa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree results:\n",
      "Accuracy:  0.7721\n",
      "Precision:  0.6801\n",
      "Recall:  0.5945\n",
      "F1_score:  0.6339 \n",
      "\n",
      "Logistic Regression results:\n",
      "Accuracy:  0.7501\n",
      "Precision:  0.9663\n",
      "Recall:  0.259\n",
      "F1_score:  0.4079 \n",
      "\n",
      "Linear SVM results:\n",
      "Accuracy:  0.8064\n",
      "Precision:  0.9104\n",
      "Recall:  0.4644\n",
      "F1_score:  0.6141 \n",
      "\n",
      "K-NearestNeighbors results:\n",
      "Accuracy:  0.7346\n",
      "Precision:  0.6359\n",
      "Recall:  0.4672\n",
      "F1_score:  0.5377 \n",
      "\n",
      "PassiveAgressive results:\n",
      "Accuracy:  0.8156\n",
      "Precision:  0.8591\n",
      "Recall:  0.5332\n",
      "F1_score:  0.6568 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "rec = {}\n",
    "f1 = {}\n",
    "\n",
    "# Metrics to retrieve after the cross-validation is performed\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{name} results:\")\n",
    "    score = cross_validate(model, X_train, y_train, scoring=scoring, cv=kf, n_jobs=-1, verbose=0)\n",
    "    print(\"Accuracy: \", round(score['test_accuracy'].mean(),4))\n",
    "    print(\"Precision: \", round(score['test_precision'].mean(),4))\n",
    "    print(\"Recall: \", round(score['test_recall'].mean(),4))\n",
    "    print(\"F1_score: \", round(score['test_f1_score'].mean(),4), '\\n')\n",
    "\n",
    "    acc[name] = score['test_accuracy'].mean()\n",
    "    prec[name] = score['test_precision'].mean()\n",
    "    rec[name] = score['test_recall'].mean()\n",
    "    f1[name] = score['test_f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7afcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "699e5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the PR curves for every model\n",
    "model_dt.fit(X_train, y_train), model_logreg.fit(X_train, y_train), model_linsvc.fit(X_train, y_train), model_knn.fit(X_train, y_train), model_paa.fit(X_train, y_train)\n",
    "\n",
    "plot_precision_recall_curve(model_dt, X_test, y_test, ax = plt.gca(),name = \"Decision Tree\")\n",
    "plot_precision_recall_curve(model_logreg, X_test, y_test, ax = plt.gca(),name = \"Log Regression\")\n",
    "plot_precision_recall_curve(model_linsvc, X_test, y_test, ax = plt.gca(),name = \"Linear SVM\")\n",
    "plot_precision_recall_curve(model_knn, X_test, y_test, ax = plt.gca(),name = \"kNN\")\n",
    "plot_precision_recall_curve(model_paa, X_test, y_test, ax = plt.gca(),name = \"PAS\")\n",
    "#plt.savefig('PR-Curve.png', dpi=600) \n",
    "plt.title('Precision-Recall curve')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c03d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
